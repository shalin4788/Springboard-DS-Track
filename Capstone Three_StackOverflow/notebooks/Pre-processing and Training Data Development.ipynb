{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prime-series",
   "metadata": {},
   "source": [
    "## I. Pre-processing and Training Data Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-haiti",
   "metadata": {},
   "source": [
    "- Goal is to create a cleaned development dataset you can use to complete the modeling step of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "finnish-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import os\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#suppress future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Show plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "executed-participant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Shalin\\\\Springboard bootcamp\\\\Springboard repo_github\\\\Springboard-DS-Track\\\\Capstone Three_StackOverflow\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deluxe-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"..\\data\\Stackoverflow_cleansed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stock-algeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455901, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inappropriate-network",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Q_Score</th>\n",
       "      <th>A_Score</th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Q_Body</th>\n",
       "      <th>Tag</th>\n",
       "      <th>A_Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>718725</th>\n",
       "      <td>864024</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>19544030</td>\n",
       "      <td>parse log file check date report result</td>\n",
       "      <td>pi need take time stamp printed codeafter ftp ...</td>\n",
       "      <td>regex, linux, bash, shell, grep</td>\n",
       "      <td>defining records correctly makes things lot ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829425</th>\n",
       "      <td>992630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22547000</td>\n",
       "      <td>force ios7 app start home screen</td>\n",
       "      <td>pi app multiple view controllers home screen p...</td>\n",
       "      <td>iphone, ios7</td>\n",
       "      <td>press home button application goes background ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193521</th>\n",
       "      <td>239114</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5483590</td>\n",
       "      <td>android listview making search filt</td>\n",
       "      <td>pis way create search filter custom list view ...</td>\n",
       "      <td>android, listview, filter, adapter, base</td>\n",
       "      <td>example list view created using base adapter s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932620</th>\n",
       "      <td>1110699</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19855350</td>\n",
       "      <td>sap abap iw31 searching user exit enh point ge...</td>\n",
       "      <td>pi working transaction iw31 task rewrite field...</td>\n",
       "      <td>sap, abap</td>\n",
       "      <td>sap release use checked include lcoihf2v find ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708303</th>\n",
       "      <td>851830</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19259210</td>\n",
       "      <td>apache modrewrite specific url</td>\n",
       "      <td>pim trying make one specific redirect googling...</td>\n",
       "      <td>apache, .htaccess, mod-rewrite, redirect</td>\n",
       "      <td>rule rewritten rewriterule quest blankparentpa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Q_Score  A_Score        Id  \\\n",
       "718725      864024        3        3  19544030   \n",
       "829425      992630        0        0  22547000   \n",
       "193521      239114        5        2   5483590   \n",
       "932620     1110699        1        0  19855350   \n",
       "708303      851830        1        0  19259210   \n",
       "\n",
       "                                                    Title  \\\n",
       "718725            parse log file check date report result   \n",
       "829425                   force ios7 app start home screen   \n",
       "193521                android listview making search filt   \n",
       "932620  sap abap iw31 searching user exit enh point ge...   \n",
       "708303                     apache modrewrite specific url   \n",
       "\n",
       "                                                   Q_Body  \\\n",
       "718725  pi need take time stamp printed codeafter ftp ...   \n",
       "829425  pi app multiple view controllers home screen p...   \n",
       "193521  pis way create search filter custom list view ...   \n",
       "932620  pi working transaction iw31 task rewrite field...   \n",
       "708303  pim trying make one specific redirect googling...   \n",
       "\n",
       "                                             Tag  \\\n",
       "718725           regex, linux, bash, shell, grep   \n",
       "829425                              iphone, ios7   \n",
       "193521  android, listview, filter, adapter, base   \n",
       "932620                                 sap, abap   \n",
       "708303  apache, .htaccess, mod-rewrite, redirect   \n",
       "\n",
       "                                                   A_Body  \n",
       "718725  defining records correctly makes things lot ea...  \n",
       "829425  press home button application goes background ...  \n",
       "193521  example list view created using base adapter s...  \n",
       "932620  sap release use checked include lcoihf2v find ...  \n",
       "708303  rule rewritten rewriterule quest blankparentpa...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sophisticated-empty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "java                                               11396\n",
       "javascript, jquery                                 10896\n",
       "android                                             9937\n",
       "javascript                                          9759\n",
       "php                                                 9687\n",
       "                                                   ...  \n",
       "json, twitter, twitter-streaming-api                   1\n",
       "python, matplotlib, jupyter, jupyter-notebook          1\n",
       "cryptography, openssl                                  1\n",
       "javascript, jquery, html, firefox, autocomplete        1\n",
       "python, canvas, tkinter, frame                         1\n",
       "Name: Tag, Length: 511628, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bright-honolulu",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gosal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gosal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vocal-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Q_Body'] = df[~df['Q_Body'].str.contains(r'(?<!\\S)(?!http|\\S*www\\.)\\S{12}')]\n",
    "#df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-american",
   "metadata": {},
   "source": [
    "**Note**: Stemming on Q_Body and A_Body column was not done in the Data Wrangling step, so resuming this step so all the 'text' columns in the dataframe are cleansed as a part of Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "shared-gather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1455901"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem_sentences(sentence):\n",
    "    tokens = sentence.split()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens if len(token) < 20 ]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "df['Q_Body'] = df['Q_Body'].apply(stem_sentences)\n",
    "df['A_Body'] = df['A_Body'].apply(stem_sentences)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stunning-hampshire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     int64\n",
       "Q_Score        int64\n",
       "A_Score        int64\n",
       "Id             int64\n",
       "Title         object\n",
       "Q_Body        object\n",
       "Tag           object\n",
       "A_Body        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "direct-context",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Q_Score</th>\n",
       "      <th>A_Score</th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Q_Body</th>\n",
       "      <th>Tag</th>\n",
       "      <th>A_Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2750</td>\n",
       "      <td>data verifications gettersetter elsewher</td>\n",
       "      <td>pim wonder good idea make stronggettersstrong ...</td>\n",
       "      <td>optimization, setter, getter, verification</td>\n",
       "      <td>valid captur separ getter setter valid method ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2750</td>\n",
       "      <td>data verifications gettersetter elsewher</td>\n",
       "      <td>pim wonder good idea make stronggettersstrong ...</td>\n",
       "      <td>optimization, setter, getter, verification</td>\n",
       "      <td>perspect maintain code think much valid setter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2750</td>\n",
       "      <td>data verifications gettersetter elsewher</td>\n",
       "      <td>pim wonder good idea make stronggettersstrong ...</td>\n",
       "      <td>optimization, setter, getter, verification</td>\n",
       "      <td>depend gener code fail fast valu set multipl p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2750</td>\n",
       "      <td>data verifications gettersetter elsewher</td>\n",
       "      <td>pim wonder good idea make stronggettersstrong ...</td>\n",
       "      <td>optimization, setter, getter, verification</td>\n",
       "      <td>might wanna check domain driven design eric ev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Q_Score  A_Score    Id  \\\n",
       "0           0        7        1  2750   \n",
       "1           1        7        3  2750   \n",
       "2           2        7        3  2750   \n",
       "3           3        7        1  2750   \n",
       "\n",
       "                                      Title  \\\n",
       "0  data verifications gettersetter elsewher   \n",
       "1  data verifications gettersetter elsewher   \n",
       "2  data verifications gettersetter elsewher   \n",
       "3  data verifications gettersetter elsewher   \n",
       "\n",
       "                                              Q_Body  \\\n",
       "0  pim wonder good idea make stronggettersstrong ...   \n",
       "1  pim wonder good idea make stronggettersstrong ...   \n",
       "2  pim wonder good idea make stronggettersstrong ...   \n",
       "3  pim wonder good idea make stronggettersstrong ...   \n",
       "\n",
       "                                          Tag  \\\n",
       "0  optimization, setter, getter, verification   \n",
       "1  optimization, setter, getter, verification   \n",
       "2  optimization, setter, getter, verification   \n",
       "3  optimization, setter, getter, verification   \n",
       "\n",
       "                                              A_Body  \n",
       "0  valid captur separ getter setter valid method ...  \n",
       "1  perspect maintain code think much valid setter...  \n",
       "2  depend gener code fail fast valu set multipl p...  \n",
       "3  might wanna check domain driven design eric ev...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "received-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Q_Body'] = df['Q_Body'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-bailey",
   "metadata": {},
   "source": [
    "#### 1. Standardize the magnitude of numeric features using a scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "broken-plaza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Q_Score', 'A_Score', 'Id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create subset of only the numeric columns\n",
    "df_numeric = df.select_dtypes(include=['int64','float'])\n",
    "print(df_numeric.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "friendly-cedar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Title', 'Q_Body', 'Tag', 'A_Body'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create subset of only the categorical variable columns\n",
    "df_categorical = df.select_dtypes(include=['object'])\n",
    "print(df_categorical.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "demonstrated-emergency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_Score</th>\n",
       "      <th>A_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.455901e+06</td>\n",
       "      <td>1.455901e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.834082e-01</td>\n",
       "      <td>1.038608e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.674276e+00</td>\n",
       "      <td>1.273145e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.000000e+00</td>\n",
       "      <td>-3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Q_Score       A_Score\n",
       "count  1.455901e+06  1.455901e+06\n",
       "mean   9.834082e-01  1.038608e+00\n",
       "std    1.674276e+00  1.273145e+00\n",
       "min   -4.000000e+00 -3.000000e+00\n",
       "25%    0.000000e+00  0.000000e+00\n",
       "50%    1.000000e+00  1.000000e+00\n",
       "75%    2.000000e+00  2.000000e+00\n",
       "max    7.000000e+00  5.000000e+00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric[['Q_Score','A_Score']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "visible-antenna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Q_Score_scaled  A_Score_scaled\n",
      "0             1.0             0.2\n",
      "1             1.0             0.6\n",
      "2             1.0             0.6\n",
      "3             1.0             0.2\n",
      "4             1.0             0.2\n"
     ]
    }
   ],
   "source": [
    "# Instantiate StandardScaler to generate the absolute values are mapped in the range [0, 1].\n",
    "# This is optional step for our dataset since there are not many outliers, however, this condenses data even better\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "# Fit SS_scaler to the data\n",
    "scaler.fit(df_numeric[['Q_Score','A_Score']])\n",
    "\n",
    "# Transform the data using the fitted scaler\n",
    "df_numeric[['Q_Score_scaled','A_Score_scaled']] = scaler.transform(df_numeric[['Q_Score','A_Score']])\n",
    "\n",
    "# Compare the origional and transformed column\n",
    "print(df_numeric[['Q_Score_scaled','A_Score_scaled']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "rational-integral",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a histogram for the 2 \n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "\n",
    "df_numeric.hist(['Q_Score_scaled','A_Score_scaled'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dependent-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non scaled column\n",
    "#df_numeric.drop(columns=['Q_Score','A_Score'], inplace=True)\n",
    "#df_numeric.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "printable-vacation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_Score_scaled</th>\n",
       "      <th>A_Score_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.455901e+06</td>\n",
       "      <td>1.455901e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.404869e-01</td>\n",
       "      <td>2.077217e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.391823e-01</td>\n",
       "      <td>2.546290e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.714286e-01</td>\n",
       "      <td>-6.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>2.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.857143e-01</td>\n",
       "      <td>4.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Q_Score_scaled  A_Score_scaled\n",
       "count    1.455901e+06    1.455901e+06\n",
       "mean     1.404869e-01    2.077217e-01\n",
       "std      2.391823e-01    2.546290e-01\n",
       "min     -5.714286e-01   -6.000000e-01\n",
       "25%      0.000000e+00    0.000000e+00\n",
       "50%      1.428571e-01    2.000000e-01\n",
       "75%      2.857143e-01    4.000000e-01\n",
       "max      1.000000e+00    1.000000e+00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric[['Q_Score_scaled','A_Score_scaled']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "private-stadium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Q_Body</th>\n",
       "      <th>Tag</th>\n",
       "      <th>A_Body</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Q_Score</th>\n",
       "      <th>A_Score</th>\n",
       "      <th>Id</th>\n",
       "      <th>Q_Score_scaled</th>\n",
       "      <th>A_Score_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data verifications gettersetter elsewher</td>\n",
       "      <td>pim wonder good idea make stronggettersstrong ...</td>\n",
       "      <td>optimization, setter, getter, verification</td>\n",
       "      <td>valid captur separ getter setter valid method ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data verifications gettersetter elsewher</td>\n",
       "      <td>pim wonder good idea make stronggettersstrong ...</td>\n",
       "      <td>optimization, setter, getter, verification</td>\n",
       "      <td>perspect maintain code think much valid setter...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data verifications gettersetter elsewher</td>\n",
       "      <td>pim wonder good idea make stronggettersstrong ...</td>\n",
       "      <td>optimization, setter, getter, verification</td>\n",
       "      <td>depend gener code fail fast valu set multipl p...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data verifications gettersetter elsewher</td>\n",
       "      <td>pim wonder good idea make stronggettersstrong ...</td>\n",
       "      <td>optimization, setter, getter, verification</td>\n",
       "      <td>might wanna check domain driven design eric ev...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data verifications gettersetter elsewher</td>\n",
       "      <td>pim wonder good idea make stronggettersstrong ...</td>\n",
       "      <td>optimization, setter, getter, verification</td>\n",
       "      <td>like implement idataerrorinfo put valid logic ...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  \\\n",
       "0  data verifications gettersetter elsewher   \n",
       "1  data verifications gettersetter elsewher   \n",
       "2  data verifications gettersetter elsewher   \n",
       "3  data verifications gettersetter elsewher   \n",
       "4  data verifications gettersetter elsewher   \n",
       "\n",
       "                                              Q_Body  \\\n",
       "0  pim wonder good idea make stronggettersstrong ...   \n",
       "1  pim wonder good idea make stronggettersstrong ...   \n",
       "2  pim wonder good idea make stronggettersstrong ...   \n",
       "3  pim wonder good idea make stronggettersstrong ...   \n",
       "4  pim wonder good idea make stronggettersstrong ...   \n",
       "\n",
       "                                          Tag  \\\n",
       "0  optimization, setter, getter, verification   \n",
       "1  optimization, setter, getter, verification   \n",
       "2  optimization, setter, getter, verification   \n",
       "3  optimization, setter, getter, verification   \n",
       "4  optimization, setter, getter, verification   \n",
       "\n",
       "                                              A_Body  Unnamed: 0  Q_Score  \\\n",
       "0  valid captur separ getter setter valid method ...           0        7   \n",
       "1  perspect maintain code think much valid setter...           1        7   \n",
       "2  depend gener code fail fast valu set multipl p...           2        7   \n",
       "3  might wanna check domain driven design eric ev...           3        7   \n",
       "4  like implement idataerrorinfo put valid logic ...           4        7   \n",
       "\n",
       "   A_Score    Id  Q_Score_scaled  A_Score_scaled  \n",
       "0        1  2750             1.0             0.2  \n",
       "1        3  2750             1.0             0.6  \n",
       "2        3  2750             1.0             0.6  \n",
       "3        1  2750             1.0             0.2  \n",
       "4        1  2750             1.0             0.2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric_scaled = pd.concat([df_categorical, df_numeric], axis=1, sort=False)\n",
    "df_numeric_scaled.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "urban-intervention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1455901 entries, 0 to 1455900\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   Title           1455901 non-null  object \n",
      " 1   Q_Body          1455901 non-null  object \n",
      " 2   Tag             1455898 non-null  object \n",
      " 3   A_Body          1455901 non-null  object \n",
      " 4   Unnamed: 0      1455901 non-null  int64  \n",
      " 5   Q_Score         1455901 non-null  int64  \n",
      " 6   A_Score         1455901 non-null  int64  \n",
      " 7   Id              1455901 non-null  int64  \n",
      " 8   Q_Score_scaled  1455901 non-null  float64\n",
      " 9   A_Score_scaled  1455901 non-null  float64\n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 111.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_numeric_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "peaceful-literature",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Q_Body  \\\n",
      "0  pim wonder good idea make stronggettersstrong ...   \n",
      "1  pim wonder good idea make stronggettersstrong ...   \n",
      "\n",
      "                                          Tag  \n",
      "0  optimization, setter, getter, verification  \n",
      "1  optimization, setter, getter, verification  \n"
     ]
    }
   ],
   "source": [
    "df_question = df_numeric_scaled.drop(columns=['Title', 'A_Body', 'Unnamed: 0', 'Id', 'Q_Score_scaled','A_Score_scaled','Q_Score','A_Score'])\n",
    "print(df_question.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-friendly",
   "metadata": {},
   "source": [
    "#### 2. Split ```Tag``` column into multiple columns delimited by ```,```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "spare-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question_tag_split = df_question['Tag'].str.split(',').apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "finite-tampa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>optimization</td>\n",
       "      <td>setter</td>\n",
       "      <td>getter</td>\n",
       "      <td>verification</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>windows</td>\n",
       "      <td>64bit</td>\n",
       "      <td>wmi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1        2              3  4\n",
       "0  optimization   setter   getter   verification  0\n",
       "7       windows    64bit      wmi              0  0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question_tags = df_question_tag_split.replace(np.nan,0).drop_duplicates()\n",
    "df_question_tags.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "soviet-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_20_tags = df_question_tag['Tag'].value_counts().head(20)\n",
    "#top_20_list = [top_20_tags]\n",
    "#top_20_tags = ['java','javascript, jquery','android', 'javascript', 'php', 'python', 'jquery', 'c#', 'php, mysql', \n",
    "#               'c', 'javascript, jquery, html', 'javascript, jquery, html, css', 'mysql, sql', 'r', 'java, android', \n",
    "#               'sql, sql-server', 'javascript, html']\n",
    "               \n",
    "#df_tag_top_20 = df_question_tag.loc[df_question_tag['Tag'].isin(top_20_tags)]\n",
    "#question_top_20 = df_question_tag[df_question_tag['Tag'].isin(top_20_tags)]\n",
    "#question_top_20_tag = question_top_20['Q_Body']\n",
    "#print(question_top_20_tag.shape[0], df_tag_top_20.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "exclusive-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511629 1455901\n"
     ]
    }
   ],
   "source": [
    "print(df_question_tags.shape[0], df_question.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "known-juice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1455901"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.concat([df_question, df_question_tags], axis = 1, sort=False)\n",
    "df_merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "extra-sterling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511628"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_merged.drop_duplicates().dropna()\n",
    "df_merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "swedish-knock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511628                                               Q_Body          Tag1     Tag2  \\\n",
      "0  pim wonder good idea make stronggettersstrong ...  optimization   setter   \n",
      "7  pive work project access wmi get inform softwa...       windows    64bit   \n",
      "\n",
      "      Tag3           Tag4 Tag5  \n",
      "0   getter   verification    0  \n",
      "7      wmi              0    0  \n"
     ]
    }
   ],
   "source": [
    "df_merged = df_merged.rename(columns={0:'Tag1',1:'Tag2',2:'Tag3',3:'Tag4',4:'Tag5'}).drop(columns={'Tag'})\n",
    "print(df_merged.shape[0], df_merged.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-computer",
   "metadata": {},
   "source": [
    "#### 3. Perform TFIDF on categorical features to fit and transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-finance",
   "metadata": {},
   "source": [
    "- We also want a measure of how unique a word is i.e. how infrequently the word occurs across all documents (inverse document frequency or idf). So, the product of tf & idf (TF-IDF) of a word gives a product of how frequent this word is in the document multiplied by how unique the word is w.r.t. the entire corpus of documents.\n",
    "- Words in the document with a high tfidf score occur frequently in the document and provide the most information about that specific document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-closure",
   "metadata": {},
   "source": [
    "**TFIDF on** \n",
    "- Question body and Tags\n",
    "- Answer body and Scores (Not scope of this notebook)\n",
    "\n",
    "Furthermore, create dataframes with the vectorized values before performing modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "smart-scenario",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "vectorizer = TfidfVectorizer(max_features=200, ngram_range=(1, 1), stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "destroyed-provider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         10  abl    access       ad       add       amp  anoth     anyon  app  \\\n",
      "0  0.000000  0.0  0.000000  0.00000  0.000000  0.000000    0.0  0.000000  0.0   \n",
      "1  0.134065  0.0  0.124256  0.00000  0.000000  0.000000    0.0  0.000000  0.0   \n",
      "2  0.000000  0.0  0.000000  0.00000  0.000000  0.000000    0.0  0.271155  0.0   \n",
      "3  0.000000  0.0  0.000000  0.00000  0.000000  0.250347    0.0  0.000000  0.0   \n",
      "4  0.000000  0.0  0.000000  0.33942  0.123464  0.000000    0.0  0.000000  0.0   \n",
      "\n",
      "     applic  ...  variabl   version      view  void      want  way  web  \\\n",
      "0  0.000000  ...      0.0  0.000000  0.000000   0.0  0.000000  0.0  0.0   \n",
      "1  0.000000  ...      0.0  0.386785  0.000000   0.0  0.075587  0.0  0.0   \n",
      "2  0.000000  ...      0.0  0.000000  0.563634   0.0  0.000000  0.0  0.0   \n",
      "3  0.175741  ...      0.0  0.000000  0.000000   0.0  0.000000  0.0  0.0   \n",
      "4  0.000000  ...      0.0  0.000000  0.000000   0.0  0.169048  0.0  0.0   \n",
      "\n",
      "     window      work  write  \n",
      "0  0.000000  0.000000    0.0  \n",
      "1  0.376922  0.219904    0.0  \n",
      "2  0.000000  0.000000    0.0  \n",
      "3  0.000000  0.000000    0.0  \n",
      "4  0.000000  0.040984    0.0  \n",
      "\n",
      "[5 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "tfidf_question= vectorizer.fit_transform(df_merged['Q_Body'])\n",
    "\n",
    "# Create a DataFrame with these features\n",
    "tv_df_question = pd.DataFrame(tfidf_question.toarray(), \n",
    "                     columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(tv_df_question.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "worth-miami",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make       0.503336\n",
      "code       0.389381\n",
      "databas    0.321536\n",
      "think      0.319719\n",
      "idea       0.318799\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sample_row = tv_df_question.iloc[0]\n",
    "\n",
    "# Print the top 5 words of the sorted output\n",
    "print(sample_row.sort_values(ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "civilian-evolution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>abl</th>\n",
       "      <th>access</th>\n",
       "      <th>ad</th>\n",
       "      <th>add</th>\n",
       "      <th>amp</th>\n",
       "      <th>anoth</th>\n",
       "      <th>anyon</th>\n",
       "      <th>app</th>\n",
       "      <th>applic</th>\n",
       "      <th>...</th>\n",
       "      <th>web</th>\n",
       "      <th>window</th>\n",
       "      <th>work</th>\n",
       "      <th>write</th>\n",
       "      <th>Q_Body</th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pim wonder good idea make stronggettersstrong ...</td>\n",
       "      <td>optimization</td>\n",
       "      <td>setter</td>\n",
       "      <td>getter</td>\n",
       "      <td>verification</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.134065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376922</td>\n",
       "      <td>0.219904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         10  abl    access   ad  add  amp  anoth  anyon  app  applic  ...  \\\n",
       "0  0.000000  0.0  0.000000  0.0  0.0  0.0    0.0    0.0  0.0     0.0  ...   \n",
       "1  0.134065  0.0  0.124256  0.0  0.0  0.0    0.0    0.0  0.0     0.0  ...   \n",
       "\n",
       "   web    window      work  write  \\\n",
       "0  0.0  0.000000  0.000000    0.0   \n",
       "1  0.0  0.376922  0.219904    0.0   \n",
       "\n",
       "                                              Q_Body          Tag1     Tag2  \\\n",
       "0  pim wonder good idea make stronggettersstrong ...  optimization   setter   \n",
       "1                                                NaN           NaN      NaN   \n",
       "\n",
       "      Tag3           Tag4  Tag5  \n",
       "0   getter   verification     0  \n",
       "1      NaN            NaN   NaN  \n",
       "\n",
       "[2 rows x 206 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([tv_df_question, df_merged], axis = 1, sort=False)\n",
    "df_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "endangered-hindu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842097          10  abl    access   ad  add       amp  anoth     anyon  app  \\\n",
      "0  0.000000  0.0  0.000000  0.0  0.0  0.000000    0.0  0.000000  0.0   \n",
      "1  0.134065  0.0  0.124256  0.0  0.0  0.000000    0.0  0.000000  0.0   \n",
      "2  0.000000  0.0  0.000000  0.0  0.0  0.000000    0.0  0.271155  0.0   \n",
      "3  0.000000  0.0  0.000000  0.0  0.0  0.250347    0.0  0.000000  0.0   \n",
      "\n",
      "     applic  ...  way  web    window      work  write          Tag1     Tag2  \\\n",
      "0  0.000000  ...  0.0  0.0  0.000000  0.000000    0.0  optimization   setter   \n",
      "1  0.000000  ...  0.0  0.0  0.376922  0.219904    0.0           NaN      NaN   \n",
      "2  0.000000  ...  0.0  0.0  0.000000  0.000000    0.0           NaN      NaN   \n",
      "3  0.175741  ...  0.0  0.0  0.000000  0.000000    0.0           NaN      NaN   \n",
      "\n",
      "      Tag3           Tag4  Tag5  \n",
      "0   getter   verification     0  \n",
      "1      NaN            NaN   NaN  \n",
      "2      NaN            NaN   NaN  \n",
      "3      NaN            NaN   NaN  \n",
      "\n",
      "[4 rows x 205 columns]\n"
     ]
    }
   ],
   "source": [
    "df_final = df_final.drop(columns={'Q_Body'})\n",
    "print(df_final.shape[0], df_final.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "toxic-thumb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181159      10  abl  access   ad       add  amp  anoth  anyon  app    applic  ...  \\\n",
      "0   0.0  0.0     0.0  0.0  0.000000  0.0    0.0    0.0  0.0  0.000000  ...   \n",
      "7   0.0  0.0     0.0  0.0  0.134123  0.0    0.0    0.0  0.0  0.000000  ...   \n",
      "9   0.0  0.0     0.0  0.0  0.000000  0.0    0.0    0.0  0.0  0.227786  ...   \n",
      "13  0.0  0.0     0.0  0.0  0.000000  0.0    0.0    0.0  0.0  0.000000  ...   \n",
      "\n",
      "    way  web    window  work    write          Tag1                   Tag2  \\\n",
      "0   0.0  0.0  0.000000   0.0  0.00000  optimization                 setter   \n",
      "7   0.0  0.0  0.000000   0.0  0.00000       windows                  64bit   \n",
      "9   0.0  0.0  0.000000   0.0  0.51629           sql             sql-server   \n",
      "13  0.0  0.0  0.732616   0.0  0.00000       asp.net   business-logic-layer   \n",
      "\n",
      "                 Tag3           Tag4  Tag5  \n",
      "0              getter   verification     0  \n",
      "7                 wmi              0     0  \n",
      "9            database        diagram     0  \n",
      "13   objectdatasource              0     0  \n",
      "\n",
      "[4 rows x 205 columns]\n"
     ]
    }
   ],
   "source": [
    "df_final = df_final.dropna()\n",
    "print(df_final.shape[0], df_final.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "smart-secretariat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10        float64\n",
       "abl       float64\n",
       "access    float64\n",
       "ad        float64\n",
       "add       float64\n",
       "           ...   \n",
       "Tag1       object\n",
       "Tag2       object\n",
       "Tag3       object\n",
       "Tag4       object\n",
       "Tag5       object\n",
       "Length: 205, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-machine",
   "metadata": {},
   "source": [
    "#### 4. Convert categorical variables into numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "desperate-hormone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c#            18329\n",
      "java          15608\n",
      "php           12673\n",
      "javascript    10157\n",
      "c++            7666\n",
      "Name: Tag1, dtype: int64  jquery     3772\n",
      " .net       3705\n",
      " asp.net    2723\n",
      "0           2598\n",
      " html       2441\n",
      "Name: Tag2, dtype: int64 0        30219\n",
      " html      966\n",
      " ios       827\n",
      " ajax      728\n",
      " css       683\n",
      "Name: Tag3, dtype: int64 0        93765\n",
      " json      205\n",
      " ajax      186\n",
      " ipad      169\n",
      " css       165\n",
      "Name: Tag4, dtype: int64 0                  148171\n",
      " cordova               41\n",
      " css3                  35\n",
      " drop-down-menu        35\n",
      " post                  35\n",
      "Name: Tag5, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_final['Tag1'].value_counts().head(5), df_final['Tag2'].value_counts().head(5), \n",
    "      df_final['Tag3'].value_counts().head(5), df_final['Tag4'].value_counts().head(5), \n",
    "      df_final['Tag5'].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-reputation",
   "metadata": {},
   "source": [
    "**Apply one hot encoding using ```get_dummies```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dramatic-contract",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    10  abl  access   ad       add  amp  anoth  anyon  app  applic  ...  way  \\\n",
      "0  0.0  0.0     0.0  0.0  0.000000  0.0    0.0    0.0  0.0     0.0  ...  0.0   \n",
      "7  0.0  0.0     0.0  0.0  0.134123  0.0    0.0    0.0  0.0     0.0  ...  0.0   \n",
      "\n",
      "   web  window  work  write   Tag1   Tag2   Tag3   Tag4   Tag5  \n",
      "0  0.0     0.0   0.0    0.0  False  False  False  False  False  \n",
      "7  0.0     0.0   0.0    0.0  False  False  False  False  False  \n",
      "\n",
      "[2 rows x 205 columns] 181159\n"
     ]
    }
   ],
   "source": [
    "# Pick top 10 tags and apply one hot encoding on the dataframe to assign true/ false based on top 10 tag being found or not \n",
    "# for every questions across dataframe\n",
    "# drop_first=True is important to use, as it helps in reducing the extra column created during dummy variable creation. \n",
    "# which reduces the correlations created among dummy variables.\n",
    "\n",
    "tags = ['c#','java','php','javascript','c++','.net','asp.net','html','ios','ajax']\n",
    "df_tag = df_final[['Tag1','Tag2','Tag3','Tag4','Tag5']]\n",
    "final_top_10_tags= pd.get_dummies(df_tag.isin(tags), drop_first=True)\n",
    "\n",
    "df_ques = df_final.drop(['Tag1','Tag2','Tag3','Tag4','Tag5'], axis=1)\n",
    "\n",
    "df_final = pd.concat([df_ques, final_top_10_tags], axis=1)\n",
    "print(df_final.head(2), df_final.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "alpha-spanish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>abl</th>\n",
       "      <th>access</th>\n",
       "      <th>ad</th>\n",
       "      <th>add</th>\n",
       "      <th>amp</th>\n",
       "      <th>anoth</th>\n",
       "      <th>anyon</th>\n",
       "      <th>app</th>\n",
       "      <th>applic</th>\n",
       "      <th>...</th>\n",
       "      <th>way</th>\n",
       "      <th>web</th>\n",
       "      <th>window</th>\n",
       "      <th>work</th>\n",
       "      <th>write</th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88535</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.38054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        10  abl   access   ad  add  amp  anoth  anyon  app  applic  ...  way  \\\n",
       "88535  0.0  0.0  0.38054  0.0  0.0  0.0    0.0    0.0  0.0     0.0  ...  0.0   \n",
       "52250  0.0  0.0  0.00000  0.0  0.0  0.0    0.0    0.0  0.0     0.0  ...  0.0   \n",
       "\n",
       "       web  window      work  write  Tag1  Tag2  Tag3  Tag4  Tag5  \n",
       "88535  0.0     0.0  0.224489    0.0     0     0     0     0     0  \n",
       "52250  0.0     0.0  0.000000    0.0     0     0     0     0     0  \n",
       "\n",
       "[2 rows x 205 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[['Tag1','Tag2','Tag3','Tag4','Tag5']] *= 1\n",
    "df_final.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-purse",
   "metadata": {},
   "source": [
    "#### 5. Training data development and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "colored-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_question_df, test_question_df = train_test_split(df_final, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "charged-undergraduate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126811 54348\n"
     ]
    }
   ],
   "source": [
    "print(train_question_df.shape[0], test_question_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "operating-lecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        10  abl  access   ad  add       amp     anoth  anyon  app  applic  \\\n",
      "19281  0.0  0.0     0.0  0.0  0.0  0.000000  0.213059    0.0  0.0     0.0   \n",
      "55421  0.0  0.0     0.0  0.0  0.0  0.267905  0.000000    0.0  0.0     0.0   \n",
      "\n",
      "       ...  variabl  version  view  void      want  way  web  window  work  \\\n",
      "19281  ...      0.0      0.0   0.0   0.0  0.135192  0.0  0.0     0.0   0.0   \n",
      "55421  ...      0.0      0.0   0.0   0.0  0.000000  0.0  0.0     0.0   0.0   \n",
      "\n",
      "       write  \n",
      "19281    0.0  \n",
      "55421    0.0  \n",
      "\n",
      "[2 rows x 200 columns]        Tag1  Tag2  Tag3  Tag4  Tag5\n",
      "19281     0     0     0     0     0\n",
      "55421     0     0     0     0     0\n"
     ]
    }
   ],
   "source": [
    "X_train = train_question_df.loc[:, '10':'write']\n",
    "y_train = train_question_df.loc[:, 'Tag1':'Tag5']\n",
    "print(X_train.head(2), y_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "integral-swift",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         10  abl  access   ad  add  amp  anoth  anyon       app  applic  ...  \\\n",
      "185871  0.0  0.0     0.0  0.0  0.0  0.0    0.0    0.0  0.000000     0.0  ...   \n",
      "123376  0.0  0.0     0.0  0.0  0.0  0.0    0.0    0.0  0.233381     0.0  ...   \n",
      "\n",
      "        variabl  version  view  void      want       way  web  window  work  \\\n",
      "185871      0.0      0.0   0.0   0.0  0.097797  0.111578  0.0     0.0   0.0   \n",
      "123376      0.0      0.0   0.0   0.0  0.000000  0.182489  0.0     0.0   0.0   \n",
      "\n",
      "        write  \n",
      "185871    0.0  \n",
      "123376    0.0  \n",
      "\n",
      "[2 rows x 200 columns]         Tag1  Tag2  Tag3  Tag4  Tag5\n",
      "185871     0     0     0     0     0\n",
      "123376     1     0     0     0     0\n"
     ]
    }
   ],
   "source": [
    "X_test = test_question_df.loc[:, '10':'write']\n",
    "y_test = test_question_df.loc[:, 'Tag1':'Tag5']\n",
    "print(X_test.head(2), y_test.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "colored-billion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        10  abl  access   ad  add       amp     anoth  anyon  app  applic  \\\n",
      "19281  0.0  0.0     0.0  0.0  0.0  0.000000  0.213059    0.0  0.0     0.0   \n",
      "55421  0.0  0.0     0.0  0.0  0.0  0.267905  0.000000    0.0  0.0     0.0   \n",
      "\n",
      "       ...  variabl  version  view  void      want  way  web  window  work  \\\n",
      "19281  ...      0.0      0.0   0.0   0.0  0.135192  0.0  0.0     0.0   0.0   \n",
      "55421  ...      0.0      0.0   0.0   0.0  0.000000  0.0  0.0     0.0   0.0   \n",
      "\n",
      "       write  \n",
      "19281    0.0  \n",
      "55421    0.0  \n",
      "\n",
      "[2 rows x 200 columns]        Tag1  Tag2  Tag3  Tag4  Tag5\n",
      "19281     0     0     0     0     0\n",
      "55421     0     0     0     0     0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head(2), y_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "occupied-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         10  abl  access   ad  add  amp  anoth  anyon       app  applic  ...  \\\n",
      "185871  0.0  0.0     0.0  0.0  0.0  0.0    0.0    0.0  0.000000     0.0  ...   \n",
      "123376  0.0  0.0     0.0  0.0  0.0  0.0    0.0    0.0  0.233381     0.0  ...   \n",
      "\n",
      "        variabl  version  view  void      want       way  web  window  work  \\\n",
      "185871      0.0      0.0   0.0   0.0  0.097797  0.111578  0.0     0.0   0.0   \n",
      "123376      0.0      0.0   0.0   0.0  0.000000  0.182489  0.0     0.0   0.0   \n",
      "\n",
      "        write  \n",
      "185871    0.0  \n",
      "123376    0.0  \n",
      "\n",
      "[2 rows x 200 columns]         Tag1  Tag2  Tag3  Tag4  Tag5\n",
      "185871     0     0     0     0     0\n",
      "123376     1     0     0     0     0\n"
     ]
    }
   ],
   "source": [
    "print(X_test.head(2), y_test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-silly",
   "metadata": {},
   "source": [
    "## II. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-programming",
   "metadata": {},
   "source": [
    "Perform multi label classification modeling on the ```df_final``` dataframe that has Q_Body and Tag columns in order to determine what tag will be classified for a given question based on the body of question posted on Stackoverflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-minute",
   "metadata": {},
   "source": [
    "### Multi-Label Classification Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-macintosh",
   "metadata": {},
   "source": [
    "- To solve multi-label classification problem, we can decompose it into multiple independent binary classification problems (one per category) using one-to-rest strategy, where we will build multiple independent classifiers and, for an unseen instance, choose the class for which the confidence is maximized.\n",
    "- The main assumption here is that the labels are mutually exclusive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-alignment",
   "metadata": {},
   "source": [
    "#### 1. Import all ML libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "alive-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import ML models:\n",
    "import time\n",
    "from sklearn import tree,metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.svm import LinearSVC\n",
    "#from sklearn.linear_model import Perceptron\n",
    "#from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "#from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,ExtraTreesClassifier\n",
    "#from sklearn import tree,metrics\n",
    "#from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, precision_recall_fscore_support as score, hamming_loss, make_scorer\n",
    "#from sklearn.metrics import plot_confusion_matrix, classification_report, confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-bangladesh",
   "metadata": {},
   "source": [
    "#### 2. Apply Deep learning applied model using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "median-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_jacard(y_true,y_pred):\n",
    "    '''\n",
    "    see https://en.wikipedia.org/wiki/Multi-label_classification#Statistics_and_evaluation_metrics\n",
    "    '''\n",
    "    jacard = np.minimum(y_true,y_pred).sum(axis=1) / np.maximum(y_true,y_pred).sum(axis=1)\n",
    "    \n",
    "    return jacard.mean()*100\n",
    "\n",
    "def print_score(y_pred, clf):\n",
    "    print(\"Clf: \", clf.__class__.__name__)\n",
    "    print(\"Jacard score: {}\".format(avg_jacard(y_test, y_pred)))\n",
    "    print(\"Hamming loss: {}\".format(hamming_loss(y_pred, y_test)*100))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "tested-rogers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Sigmoid Activation  Model====\n",
      "Epoch 1/5\n",
      "126811/126811 [==============================] - 53s 416us/step - loss: 0.5167\n",
      "Epoch 2/5\n",
      "126811/126811 [==============================] - 53s 416us/step - loss: 0.2110\n",
      "Epoch 3/5\n",
      "126811/126811 [==============================] - 53s 418us/step - loss: 0.1534\n",
      "Epoch 4/5\n",
      "126811/126811 [==============================] - 53s 419us/step - loss: 0.1445\n",
      "Epoch 5/5\n",
      "126811/126811 [==============================] - 54s 424us/step - loss: 0.1414\n",
      "====Sigmoid Activation  Model====\n",
      "Jacard score: 17.43048570366099\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5000, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "print('====Sigmoid Activation  Model====')\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=2000)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "np.argmax(y_pred, axis=1)\n",
    "# score = compare preds and y_test\n",
    "print('====Sigmoid Activation  Model====')\n",
    "print(\"Jacard score: {}\".format(avg_jacard(y_test, y_pred)))\n",
    "print(\"Hamming loss: {}\".format(hamming_loss(y_pred, y_test)*100))\n",
    "#print('F1 score:', f1_score(y_test,y_pred, average = 'weighted'))\n",
    "#print('Precision score:' , round(metrics.precision_score(y_test,y_pred, average='weighted'),3))\n",
    "#print('Accuracy:', round(metrics.accuracy_score(y_test,y_pred),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-debate",
   "metadata": {},
   "source": [
    "- Not a great score. Lets try other multilabel classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-question",
   "metadata": {},
   "source": [
    "#### 3. Apply other multi label classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-association",
   "metadata": {},
   "source": [
    "Some of the multi-label classification models are\n",
    "\n",
    "- tree.DecisionTreeClassifier\n",
    "- tree.ExtraTreeClassifier\n",
    "- ensemble.ExtraTreesClassifier\n",
    "- neighbors.KNeighborsClassifier\n",
    "- neural_network.MLPClassifier\n",
    "- neighbors.RadiusNeighborsClassifier\n",
    "- ensemble.RandomForestClassifier\n",
    "- linear_model.RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "native-function",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier() Classifier\n",
      "Clf:  OneVsRestClassifier\n",
      "Jacard score: 26.80826478113737\n",
      "Hamming loss: 9.789872672407448\n",
      "---\n",
      "KNeighborsClassifier() Classifier\n",
      "Clf:  OneVsRestClassifier\n",
      "Jacard score: 24.293587612632315\n",
      "Hamming loss: 9.553985427246634\n",
      "---\n",
      "MLPClassifier() Classifier\n",
      "Clf:  OneVsRestClassifier\n",
      "Jacard score: 26.543977451711847\n",
      "Hamming loss: 9.782512695959374\n",
      "---\n",
      "LogisticRegression() Classifier\n",
      "Clf:  OneVsRestClassifier\n",
      "Jacard score: 0.0\n",
      "Hamming loss: 8.476116876425996\n",
      "---\n",
      "RandomForestClassifier() Classifier\n",
      "Clf:  OneVsRestClassifier\n",
      "Jacard score: 9.441685934124248\n",
      "Hamming loss: 8.792227864870833\n",
      "---\n",
      "ExtraTreeClassifier() Classifier\n",
      "Clf:  OneVsRestClassifier\n",
      "Jacard score: 27.376290494838017\n",
      "Hamming loss: 9.759328770147937\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#https://gist.github.com/jnothman/4807b1b0266613c20ba4d1f88d0f8cf5\n",
    "import warnings\n",
    "import sklearn\n",
    "warnings.simplefilter('ignore')\n",
    "from sklearn import *\n",
    "\n",
    "#dummy = DummyClassifier()\n",
    "#sgd = SGDClassifier()\n",
    "#lr = LogisticRegression()\n",
    "#mn = MultinomialNB()\n",
    "#svc = LinearSVC()\n",
    "#perceptron = Perceptron()\n",
    "#pac = PassiveAggressiveClassifier()\n",
    "#mlpc = MLPClassifier()\n",
    "#rfc = RandomForestClassifier()\n",
    "#for classifier in [dummy, svc, perceptron, pac, mlpc, rfc]:\n",
    "for classifier in [tree.DecisionTreeClassifier(),\n",
    "                   KNeighborsClassifier(),\n",
    "                   MLPClassifier(),\n",
    "                   #multioutput.MultiOutputClassifier(linear_model.LogisticRegression()),\n",
    "                   #multiclass.OneVsRestClassifier(linear_model.LogisticRegression()),\n",
    "                   LogisticRegression(),\n",
    "                   RandomForestClassifier(),\n",
    "                   ExtraTreeClassifier()]:\n",
    "    clf = OneVsRestClassifier(classifier)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred[y_pred>=0.5] = 1\n",
    "    y_pred[y_pred<0.5] = 0\n",
    "    print(\"{} Classifier\".format(classifier))\n",
    "    print_score(y_pred, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "nuclear-evening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsRestClassifier(estimator=GradientBoostingClassifier(learning_rate=0.02,\n",
      "                                                         n_estimators=70)) Classifier\n",
      "Clf:  OneVsRestClassifier\n",
      "Jacard score: 0.013025356026398054\n",
      "Hamming loss: 8.47464488113638\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "gb_model = OneVsRestClassifier(GradientBoostingClassifier(n_estimators=70, max_depth=3, learning_rate=.02))\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "y_pred_gb[y_pred_gb>=0.5] = 1\n",
    "y_pred_gb[y_pred_gb<0.5] = 0\n",
    "print(\"{} Classifier\".format(classifier))\n",
    "print_score(y_pred_gb, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-clinic",
   "metadata": {},
   "source": [
    "- Seems like OnevsRestClassifier applied on ExtraTreeClassifier() classifier model performs best followed by DecisionTreeClassifier() and MLPClassifier() models, so we will perform hyperparameter tuning using GridSearchCV() on the ExtraTreeClasifier() and MLPClassifier()\n",
    "- We can keep DecisionTreeClassifier() out of the scope since Decision tree model is more susceptible to overfitting and performance erosion as number of trees increase, we will perform GridSearchCV and hyperparameter tuning on the other 2 models.\n",
    "\n",
    "- LogisticRegression and GradientBoostingClassifer are the worst and shouldn't be even considered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-hobby",
   "metadata": {},
   "source": [
    "#### 4a. GridSearch CV on OnevsRestClassifer(MLPClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "short-determination",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', StandardScaler(with_mean=False)),\n",
      "                ('clf',\n",
      "                 OneVsRestClassifier(estimator=MLPClassifier(activation='tanh',\n",
      "                                                             alpha=1.0,\n",
      "                                                             early_stopping=True,\n",
      "                                                             learning_rate='adaptive',\n",
      "                                                             max_iter=1000,\n",
      "                                                             random_state=9000,\n",
      "                                                             solver='sgd')))])\n",
      "{'clf__estimator__activation': 'tanh', 'clf__estimator__alpha': 1.0, 'clf__estimator__hidden_layer_sizes': (100,), 'clf__estimator__max_iter': 1000}\n",
      "0.24899427341523916\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/53827524/python-scikit-learn-mlpclassifier-error-when-putting-in-pipeline\n",
    "\n",
    "model_mlp = Pipeline([('scale',StandardScaler(with_mean=False)),\n",
    "                     ('clf',OneVsRestClassifier(MLPClassifier(learning_rate = 'adaptive', \n",
    "                                                              solver = 'sgd', \n",
    "                                                              early_stopping = True, \n",
    "                                                              random_state=9000)))])\n",
    "\n",
    "parameters = {'clf__estimator__alpha':[10.0 ** ~ np.arange(1,7).any()],\n",
    "    'clf__estimator__hidden_layer_sizes': [(100,),(50,)],\n",
    "    'clf__estimator__max_iter': [1000,500],\n",
    "    'clf__estimator__activation':('relu','tanh')}\n",
    "\n",
    "gs_cv_model_mlp = GridSearchCV(model_mlp, parameters, cv=3, n_jobs=-1, scoring=make_scorer(avg_jacard,greater_is_better=True)) \n",
    "\n",
    "gs_cv_model_mlp.fit(X_train, y_train)\n",
    "\n",
    "print(gs_cv_model_mlp.best_estimator_) \n",
    "print(gs_cv_model_mlp.best_params_) \n",
    "print(gs_cv_model_mlp.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "opened-sleep",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Hyperparameter tuned MLP Classifier model====\n",
      "Training time is: 72.74442219734192\n",
      "Prediction time is: 106.35685610771179\n",
      "Jacard score: 0.10410340938665742\n",
      "Hamming loss: 8.475012879958783\n",
      "F1 score: 0.0020799029378628995\n",
      "Precision score: 0.522\n",
      "Accuracy: 0.576\n"
     ]
    }
   ],
   "source": [
    "mlp_final = Pipeline(steps=[('scale', StandardScaler(with_mean=False)),\n",
    "                ('clf',\n",
    "                 OneVsRestClassifier(estimator=MLPClassifier(activation='tanh',\n",
    "                                                             alpha=1.0,\n",
    "                                                             early_stopping=True,\n",
    "                                                             learning_rate='adaptive',\n",
    "                                                             max_iter=1000,\n",
    "                                                             random_state=9000,\n",
    "                                                             solver='sgd')))])\n",
    "\n",
    "start_train = time.time()\n",
    "mlp_final.fit(X_train, y_train)  \n",
    "end_train = time.time()\n",
    "training_time_mlp_final = (end_train - start_train)\n",
    "\n",
    "start_predict = time.time()\n",
    "y_predictions_mlp_final = mlp_final.predict(X_test)\n",
    "end_predict = time.time()\n",
    "prediction_time_mlp_final = (end_predict - start_predict)\n",
    "\n",
    "print('====Hyperparameter tuned MLP Classifier model====')\n",
    "print('Training time is:', training_time_mlp_final)\n",
    "print('Prediction time is:', prediction_time_mlp_final)\n",
    "print(\"Jacard score: {}\".format(avg_jacard(y_test, y_predictions_mlp_final)))\n",
    "print(\"Hamming loss: {}\".format(hamming_loss(y_predictions_mlp_final, y_test)*100))\n",
    "print('F1 score:', f1_score(y_test,y_predictions_mlp_final, average = 'weighted'))\n",
    "print('Precision score:' , round(metrics.precision_score(y_test,y_predictions_mlp_final, average='weighted'),3))\n",
    "print('Accuracy:', round(metrics.accuracy_score(y_test,y_predictions_mlp_final),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-referral",
   "metadata": {},
   "source": [
    "#### 4b. GridSearch CV on OnevsRestClassifer(ExtraTreeClassifer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "elder-doctrine",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', StandardScaler(with_mean=False)),\n",
      "                ('clf',\n",
      "                 OneVsRestClassifier(estimator=ExtraTreesClassifier(criterion='entropy',\n",
      "                                                                    max_features=100,\n",
      "                                                                    min_samples_leaf=5,\n",
      "                                                                    min_samples_split=5)))])\n",
      "{'clf__estimator__criterion': 'entropy', 'clf__estimator__max_features': 100}\n",
      "7.401444156398757\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/53827524/python-scikit-learn-mlpclassifier-error-when-putting-in-pipeline\n",
    "\n",
    "model_etc = Pipeline([('scale',StandardScaler(with_mean=False)),\n",
    "                     ('clf',OneVsRestClassifier(ensemble.ExtraTreesClassifier(n_estimators=100,\n",
    "                                                                    min_samples_split= 5,\n",
    "                                                                    min_samples_leaf= 5)))])\n",
    "\n",
    "parameters = {'clf__estimator__max_features': [50,100],\n",
    "    'clf__estimator__criterion':['gini','entropy']}\n",
    "\n",
    "gs_cv_model_etc = GridSearchCV(model_etc, parameters, cv=3, n_jobs=-1, scoring=make_scorer(avg_jacard,greater_is_better=True)) \n",
    "\n",
    "gs_cv_model_etc.fit(X_train, y_train)\n",
    "\n",
    "print(gs_cv_model_etc.best_estimator_) \n",
    "print(gs_cv_model_etc.best_params_) \n",
    "print(gs_cv_model_etc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "canadian-hardwood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Hyperparameter tuned ExtraTreesClassifier model====\n",
      "Training time is: 316.8129987716675\n",
      "Prediction time is: 6.824744462966919\n",
      "Jacard score: 0.5126437771938138\n",
      "Hamming loss: 8.498564804592625\n",
      "F1 score: 0.010200582890450881\n",
      "Precision score: 0.397\n",
      "Accuracy: 0.575\n"
     ]
    }
   ],
   "source": [
    "etc_final = Pipeline([('scale',StandardScaler(with_mean=False)),\n",
    "                     ('clf',OneVsRestClassifier(ensemble.ExtraTreesClassifier(n_estimators=200,\n",
    "                                                                    min_samples_split= 5,\n",
    "                                                                    criterion='entropy',\n",
    "                                                                    min_samples_leaf= 5)))])\n",
    "\n",
    "start_train = time.time()\n",
    "etc_final.fit(X_train, y_train)  \n",
    "end_train = time.time()\n",
    "training_time_etc_final = (end_train - start_train)\n",
    "\n",
    "start_predict = time.time()\n",
    "y_predictions_etc_final = etc_final.predict(X_test)\n",
    "end_predict = time.time()\n",
    "prediction_time_etc_final = (end_predict - start_predict)\n",
    "\n",
    "print('====Hyperparameter tuned ExtraTreesClassifier model====')\n",
    "print('Training time is:', training_time_etc_final)\n",
    "print('Prediction time is:', prediction_time_etc_final)\n",
    "print(\"Jacard score: {}\".format(avg_jacard(y_test, y_predictions_etc_final)))\n",
    "print(\"Hamming loss: {}\".format(hamming_loss(y_predictions_etc_final, y_test)*100))\n",
    "print('F1 score:', f1_score(y_test,y_predictions_etc_final, average = 'weighted'))\n",
    "print('Precision score:' , round(metrics.precision_score(y_test,y_predictions_etc_final, average='weighted'),3))\n",
    "print('Accuracy:', round(metrics.accuracy_score(y_test,y_predictions_etc_final),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-south",
   "metadata": {},
   "source": [
    "#### 5. Make probability prediction for each question based on ```tag``` classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "satisfied-conclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45295944 0.         0.         0.         0.        ]\n",
      " [0.45654311 0.         0.         0.         0.        ]\n",
      " [0.41728194 0.         0.         0.         0.        ]\n",
      " ...\n",
      " [0.43436284 0.         0.         0.         0.        ]\n",
      " [0.3825305  0.         0.         0.         0.        ]\n",
      " [0.43536295 0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tag_predict_prob = etc_final.predict_proba(X_test)\n",
    "print(tag_predict_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-jenny",
   "metadata": {},
   "source": [
    "- **We will choose ```Accuracy``` as the final metric to evaluate performance**\n",
    "- **Accuracy for ```MLPClassifier()``` model based on ```GridSearchCV``` and  hyperparameter tuning applied comes out to 0.576 which is a tad better than ```ExtraTreesClassifier()```, however since the prediction time is signficantly low for Ensemeble ```ExtraTreesClassifer()``` model, we will choose that as the final model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-breakdown",
   "metadata": {},
   "source": [
    "#### 6. Feature importance and Confusion matrix\n",
    "- Plotting the feature importances is one way that you can gain a perspective on which features are driving the model predictions.\n",
    "- Creating confusion matrix \n",
    "\n",
    "(@Tony Paek - Please review on why this isn't returning output for multi label classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "partial-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_impts = [] \n",
    "#for clf in etc_final.estimators_:\n",
    "#    feat_impts.append(clf.feature_importances_)\n",
    "\n",
    "#np.mean(feat_impts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "respected-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_importance = etc_final.estimators_[i].feature_importances_\n",
    "## make importances relative to max importance\n",
    "#feature_importance = 100.0 * (feature_importance / feature_importance.max())[:30]\n",
    "#sorted_idx = np.argsort(feature_importance)[:30]\n",
    "\n",
    "#pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "#print(pos.size)\n",
    "#sorted_idx.size\n",
    "#plt.figure(figsize=(15,15))\n",
    "#plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "#plt.yticks(pos, X.columns[sorted_idx])\n",
    "#plt.xlabel('Relative Importance', fontsize=10)\n",
    "#plt.title('Variable Importance')\n",
    "#plt.savefig(\"./figures/Variables with most significant feature Importance.png\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "proprietary-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnf_matrix= confusion_matrix(y_test,y_predictions_mlp_final.round())\n",
    "\n",
    "#_ = plot_confusion_matrix(mlp_final, X_test, y_test) \n",
    "#_ = plt.title('Insincere questions - 1, Sincere questions - 0')\n",
    "#_ = plt.show()\n",
    "\n",
    "#plt.savefig(\"./figures/Confusion matrix_validation_data.png\")\n",
    "#print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "early-opera",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/ExtraTreesClassifierModel_MultiLabelclassification.joblib']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(etc_final,  '../models/ExtraTreesClassifierModel_MultiLabelclassification.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-financing",
   "metadata": {},
   "source": [
    "#### 7. Actual test data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "realistic-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_etc = joblib.load('../models/ExtraTreesClassifierModel_MultiLabelclassification.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "super-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_actual_test = test_question_df.loc[:, '10':'write']\n",
    "y_actual_test = test_question_df.loc[:, 'Tag1':'Tag5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "twenty-natural",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Unseen test dataset - training and prediction times====\n",
      "Training time is: 101.91666412353516\n",
      "Prediction time is: 6.004774570465088\n"
     ]
    }
   ],
   "source": [
    "#Fit the final test dataset\n",
    "start_train = time.time()\n",
    "loaded_etc.fit(X_actual_test, y_actual_test)\n",
    "end_train = time.time()\n",
    "training_time_etc_test = (end_train - start_train)\n",
    "\n",
    "start_predict = time.time()\n",
    "#Perform prediction\n",
    "y_test_predictions_etc = loaded_etc.predict(X_actual_test)\n",
    "end_predict = time.time()\n",
    "predict_time_etc_test = (end_predict - start_predict)\n",
    "\n",
    "print('====Unseen test dataset - training and prediction times====')\n",
    "print('Training time is:', training_time_etc_test)\n",
    "print('Prediction time is:', predict_time_etc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "confidential-springer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Unseen test dataset - Scores====\n",
      "Jacard score: 86.61489066296426\n",
      "Hamming loss: 1.1352763671156252\n",
      "F1 score: 0.9282741624235661\n",
      "Precision score: 0.999\n",
      "Accuracy: 0.943\n"
     ]
    }
   ],
   "source": [
    "print('====Unseen test dataset - Scores====')\n",
    "print(\"Jacard score: {}\".format(avg_jacard(y_actual_test, y_test_predictions_etc)))\n",
    "print(\"Hamming loss: {}\".format(hamming_loss(y_test_predictions_etc, y_actual_test)*100))\n",
    "print('F1 score:', f1_score(y_actual_test,y_test_predictions_etc, average = 'weighted'))\n",
    "print('Precision score:' , round(metrics.precision_score(y_actual_test,y_test_predictions_etc, average='weighted'),3))\n",
    "print('Accuracy:', round(metrics.accuracy_score(y_actual_test,y_test_predictions_etc),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-remove",
   "metadata": {},
   "source": [
    "#### 8. Probability prediction of tag accuracy for each question (on unseen test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "isolated-spirit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33928781 0.         0.         0.         0.        ]\n",
      " [0.55109782 0.         0.         0.         0.        ]\n",
      " [0.36349489 0.         0.         0.         0.        ]\n",
      " ...\n",
      " [0.5110637  0.         0.         0.         0.        ]\n",
      " [0.58401409 0.         0.         0.         0.        ]\n",
      " [0.52764122 0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "unseen_tag_predict_prob = loaded_etc.predict_proba(X_actual_test)\n",
    "print(unseen_tag_predict_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-process",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-bloom",
   "metadata": {},
   "source": [
    "**Prediction on unseen test data**\n",
    "- The accuracy comes to around 0.94 and Jaccard score - 0.86, f1-weighted score - 0 (using cross validation)\n",
    "- Hamming Loss was also 1.13 which indicates a very small fraction of wrong labels to the total number of labels in the unseen dataset \n",
    "- Also the prediction time is very low - 6 seconds\n",
    "- The model was fit very well and has been able to predict data on unseen test dataset pretty well, which indicates that the model performed very well and didn't overfit on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-ranking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
